{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load get_transaction_stats.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import ttest_ind\n",
    "import datetime\n",
    "\n",
    "today = datetime.datetime.today().date()\n",
    "\n",
    "\n",
    "def read_raw_trans(root, file_name, file_head):\n",
    "    \"\"\"\n",
    "    get the raw transaction data (e.g. summary1.txt)\n",
    "    :param root: direct to the folder that contains the file\n",
    "    :param file_name: the name of the file (e.g. summary1 thru Feb 7.txt)\n",
    "    :param file_head: column names of the file\n",
    "    :return: the formatted file\n",
    "    \"\"\"\n",
    "    trans_df = pd.read_table(os.path.join(root, file_name), sep=',', header=None)\n",
    "    header = pd.read_table(os.path.join(root, file_head), sep=',', header=None)\n",
    "    trans_df.columns = list(header[0])\n",
    "    trans_df.dropna(inplace=True)\n",
    "    if 'Date' not in trans_df.columns:\n",
    "        trans_df['Date'] = pd.to_datetime(\n",
    "            (trans_df['Year'] * 10000 + trans_df['Month'] * 100 + trans_df['Day']).map(str))\n",
    "        trans_df.drop(['Year', 'Month', 'Day', '16?'], axis=1, inplace=True)\n",
    "    if 'Position' not in trans_df.columns:\n",
    "        trans_df = trans_df.rename(columns={'Position (Buy or Sell)': 'Position',\n",
    "                                            'Options (Option related or not)': 'Options'})\n",
    "    if 'ExecutiveSECID' not in trans_df.columns:\n",
    "        trans_df = trans_df.rename(columns={'SEC_Insider_ID': 'ExecutiveSECID'})\n",
    "           \n",
    "\n",
    "    return trans_df\n",
    "\n",
    "\n",
    "def exclude_outliers(trans_df, price_cut=1, options=False, market_cap_thre=0, cols_to_trim=None,\n",
    "                     thre_truncation=10,\n",
    "                     iter_truncation=5,\n",
    "                     thre_wins_upper=99,\n",
    "                     thre_wins_lower=1):\n",
    "    \"\"\"\n",
    "    :param trans_df: transaction history file\n",
    "    :param price_cut: ignore penny stocks or stock of this price\n",
    "    :param options: whether to consider option related transactions\n",
    "    :param market_cap_thre:\n",
    "    :param cols_to_trim:\n",
    "    :param thre_truncation:\n",
    "    :param iter_truncation:\n",
    "    :param thre_wins_lower:\n",
    "    :param thre_wins_upper:\n",
    "    :return: return the trimmed dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    if options is False:\n",
    "        trans_df = trans_df[(trans_df['price'] >= price_cut) & (trans_df['Options'] == 0)]\n",
    "    else:\n",
    "        trans_df = trans_df[(trans_df['price'] >= price_cut)]\n",
    "\n",
    "    trans_df = trans_df[trans_df['Market_Cap (in billions)'] > market_cap_thre]\n",
    "\n",
    "    for col_to_trim in cols_to_trim:\n",
    "        lower_bound = np.percentile(a=trans_df[col_to_trim], q=thre_wins_lower)\n",
    "        upper_bound = np.percentile(a=trans_df[col_to_trim], q=thre_wins_upper)\n",
    "\n",
    "        while iter_truncation > 0:\n",
    "            trans_df[col_to_trim + '_z'] = trans_df[col_to_trim].transform(lambda x: (x - x.mean()) / x.std())\n",
    "            trans_df = trans_df[trans_df[col_to_trim + '_z'] < thre_truncation]\n",
    "            iter_truncation = iter_truncation - 1\n",
    "\n",
    "        trans_df.loc[trans_df[col_to_trim] >= upper_bound, col_to_trim] = upper_bound\n",
    "        trans_df.loc[trans_df[col_to_trim] <= lower_bound, col_to_trim] = lower_bound\n",
    "\n",
    "    return trans_df\n",
    "\n",
    "\n",
    "def get_insider_groups(gp_list, root, comp_secid):\n",
    "    \"\"\"\n",
    "    :param gp_list: the list of groups targeted\n",
    "    :param root: the path to 'TickerNameSECID.csv' file\n",
    "    :param comp_secid: file name 'TickerNameSECID.csv'\n",
    "    :return: a list of dataframe with insiders information in each group\n",
    "    \"\"\"\n",
    "    comp_secid_df = pd.read_csv(os.path.join(root, comp_secid), encoding='latin1')\n",
    "    files = os.listdir(os.path.join(os.getcwd(), 'data_out'))\n",
    "    print(files)\n",
    "    gps = []\n",
    "    found_files = []\n",
    "    for f in files:\n",
    "        if any(name in f for name in gp_list):\n",
    "            grouped_insider = pd.read_csv(os.path.join(os.getcwd(), 'data_out', f), index_col=0, encoding='latin1')\n",
    "            grouped_insider.dropna(inplace=True)\n",
    "            if 'SEC_Company_ID' not in grouped_insider.columns:\n",
    "                grouped_insider = grouped_insider.merge(comp_secid_df, on='Ticker', how='left')\n",
    "            gps.append(grouped_insider)\n",
    "            found_files.append(f.split('.')[0])\n",
    "    if 'all_groups' not in found_files:\n",
    "        all_groups = pd.concat(gps)\n",
    "        all_groups = all_groups[['ExecutiveSECID', 'SEC_Company_ID']].drop_duplicates().dropna()\n",
    "        all_groups.to_csv(os.path.join(os.getcwd(), 'data_out/all_groups.csv'), encoding='utf-8')\n",
    "        gps.append(all_groups)\n",
    "        found_files.append('all_groups')\n",
    "\n",
    "    return gps, found_files\n",
    "\n",
    "\n",
    "def get_trans(grouped_df, trans_df, financial=True):\n",
    "    \"\"\"\n",
    "    :param grouped_df: targeting group of people's dataframe. (e.g. founders, consultants etc.)\n",
    "    :param trans_df: transaction dataframe 'summary1'\n",
    "    :param financial: whether to exclude financial sector in this analysis, True is include, False is exclude\n",
    "    :return: return transaction of the targeting group and the stats of beating sector percentage;\n",
    "             return rest transactions for comparison\n",
    "    \"\"\"\n",
    "    grouped_df['key'] = (grouped_df['SEC_Company_ID'].apply(int).astype(str) + ',' +\n",
    "                         grouped_df['ExecutiveSECID'].apply(int).astype(str))\n",
    "    key_list = grouped_df['key'].tolist()\n",
    "    trans_df['key'] = (trans_df['SEC_Company_ID'].astype(str) + ',' + trans_df['ExecutiveSECID'].astype(str))\n",
    "\n",
    "    grouped_trans = trans_df[trans_df['key'].isin(key_list)]\n",
    "    other_trans = trans_df[~trans_df['key'].isin(key_list)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if financial is False:\n",
    "        grouped_trans = grouped_trans[grouped_trans['Sector_ID'] != 9]\n",
    "        other_trans = other_trans[other_trans['Sector_ID'] != 9]\n",
    "    return grouped_trans, other_trans\n",
    "\n",
    "\n",
    "def get_stats(grouped_trans, buy_sell, target_col):\n",
    "    \"\"\"\n",
    "    :param grouped_trans: transaction history of target groups\n",
    "    :param buy_sell: buy as [1], sell as [-1]\n",
    "    :param target_col: 'beating%' or 'return_12mo' etc.\n",
    "    :return: stats\n",
    "    \"\"\"\n",
    "    grouped_trans2 = grouped_trans[grouped_trans['Position'].isin(buy_sell)]\n",
    "    stats = list(pd.Series(grouped_trans2[target_col]).describe().values)\n",
    "    # number of transactions that beats sector:\n",
    "    stats.append(grouped_trans2['beating sector'].sum())\n",
    "    # percentage of beating\n",
    "    stats.append(round(grouped_trans2['beating sector'].sum()/len(grouped_trans2)*100, 2))\n",
    "    if buy_sell == [1]:\n",
    "        stats.append('buy')\n",
    "    elif buy_sell == [-1]:\n",
    "        stats.append('sell')\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "def stats_target_df(gp_trans, gp_other_trans, gp_list, target_col, titles):\n",
    "    \"\"\"\n",
    "    :param gp_trans: transaction histories with a insider groups\n",
    "    :param gp_other_trans: transaction histories with insiders not in a group\n",
    "    :param gp_list: group names of insiders\n",
    "    :param target_col: the target column you want to measure for stats 'return_12mo' or 'beating%' etc.\n",
    "    :param titles: column titles for the stats (final) dataframe, default 11 columns\n",
    "    :return: result dataframe\n",
    "    \"\"\"\n",
    "    target_df = pd.DataFrame(titles).set_index(0)\n",
    "    for i in [1, -1]:\n",
    "        for df1, df2, l in zip(gp_trans, gp_other_trans, gp_list):\n",
    "            # get stats for this group, beating%\n",
    "            num1 = get_stats(df1, buy_sell=[i], target_col=target_col)\n",
    "            # get stats for population other than this group, beating%\n",
    "            num2 = get_stats(df2, buy_sell=[i], target_col=target_col)\n",
    "            target_df[l + str(i)] = num1\n",
    "            target_df['non-' + l + str(i)] = num2\n",
    "\n",
    "    target_df = target_df.T.round(2)\n",
    "    return target_df\n",
    "\n",
    "\n",
    "def get_t_stats_df(group_trans, group_other_trans, target_col, found_files, buy_sell=[1, -1]):\n",
    "    \"\"\"\n",
    "    compare t-stats between grouped insider and outside group insiders;\n",
    "    Purpose is to see whether the grouping category makes a difference (whether the grouping is efficient).\n",
    "\n",
    "    :param group_trans: the transaction dataframe for the corresponding group\n",
    "    :param group_other_trans: the transaction dataframe for the corresponding outside-group\n",
    "    (summary1 after excluding grouped transaction)\n",
    "    :param target_col: 'net_return_1yr' or 'return_12mo'\n",
    "    :param found_files: the list of groups name found from the folder\n",
    "    :param buy_sell: buy/sell/overall to compare for group vs. outside-group\n",
    "    :return: df of t-value and p-value returned for each group vs outside-group under buy or sell or overall\n",
    "    \"\"\"\n",
    "    t_vals = []\n",
    "    p_vals = []\n",
    "\n",
    "    for gp, nongp in zip(group_trans, group_other_trans):\n",
    "        gp = gp[gp['Position'].isin(buy_sell)]\n",
    "        nongp = nongp[nongp['Position'].isin(buy_sell)]\n",
    "        s1 = gp[target_col]\n",
    "        s2 = nongp[target_col]\n",
    "\n",
    "        t, p = ttest_ind(s1, s2, equal_var=False)\n",
    "        t_vals.append(t)\n",
    "        p_vals.append(p)\n",
    "\n",
    "    stats_df = pd.DataFrame()\n",
    "    stats_df['t_value(gp_nongp)'] = t_vals\n",
    "    stats_df['p_value(gp_nongp)'] = p_vals\n",
    "    stats_df.index = found_files\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "\n",
    "def get_t_stats_df2(dfs, target_col, found_files):\n",
    "    \"\"\"\n",
    "    compare t-stats between grouped insiders' buy and sell;\n",
    "    or outside group insiders' buy and sell;\n",
    "    Purpose is to see whether buy or sell makes a difference in the group under different sample size.\n",
    "    :param dfs: grouped insiders' transaction df or outside-group insiders' transactions\n",
    "    :param target_col: 'net_return_1yr' or 'return_12mo'\n",
    "    :param found_files: the list of groups name found from the folder\n",
    "    :return: df of t-value and p-value returned for each dfs' buy compare to sell\n",
    "    \"\"\"\n",
    "    t_vals = []\n",
    "    p_vals = []\n",
    "\n",
    "    for gp in dfs:\n",
    "        gp_buy = gp[gp['Position'] == 1]\n",
    "        gp_sell = gp[gp['Position'] == -1]\n",
    "        s1 = gp_buy[target_col]\n",
    "        s2 = gp_sell[target_col]\n",
    "\n",
    "        t, p = ttest_ind(s1, s2, equal_var=False)\n",
    "        t_vals.append(t)\n",
    "        p_vals.append(p)\n",
    "\n",
    "    stats_df = pd.DataFrame()\n",
    "    stats_df['t_value(buy_sell)'] = t_vals\n",
    "    stats_df['p_value(buy_sell)'] = p_vals\n",
    "    stats_df.index = found_files\n",
    "\n",
    "    return stats_df\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     data_root = '/Users/connorchoi/Dropbox/global key advisors/Insider_Trading/Connor & Xueying/BioGroupStats/data_in'\n",
    "#     ##########################\n",
    "#     # change file name to latest summary1's name\n",
    "#     ##########################\n",
    "\n",
    "#     summary1 = read_raw_trans(data_root, 'summary1.txt', 'summary1 header.txt')\n",
    "#     summary1 = exclude_outliers(summary1, cols_to_trim=['return_12mo', 'net_return_1yr'])\n",
    "\n",
    "#     group_list = ['founder', 'academic', 'consultants', 'military', 'trader', 'all_groups']\n",
    "#     groups, found_files = get_insider_groups(group_list, data_root, 'TickerNameSECID.csv')\n",
    "\n",
    "#     group_trans = []\n",
    "#     group_other_trans = []\n",
    "#     for df in groups:\n",
    "#         df.dropna(inplace=True)\n",
    "#         # financial sector included:\n",
    "#         df_trans, df_other_trans = get_trans(df, summary1, financial=True)\n",
    "#         group_trans.append(df_trans)\n",
    "#         group_other_trans.append(df_other_trans)\n",
    "\n",
    "#     stats_titles = ['transaction count', 'mean', 'std', 'min.', '25pct', 'median',\n",
    "#                     '75pct', 'max.', 'beat count', 'beat/transaction', 'position']\n",
    "\n",
    "#     total_return_stats_df = stats_target_df(group_trans, group_other_trans,\n",
    "#                                             found_files, 'return_12mo', stats_titles)\n",
    "#     total_return_stats_df.to_csv('data_out/stats/Return12mo_stats{}.csv'.format(today))\n",
    "#     beating_stats_df = stats_target_df(group_trans, group_other_trans,\n",
    "#                                        found_files, 'net_return_1yr', stats_titles)\n",
    "#     beating_stats_df.to_csv('data_out/stats/Net_return_1yr_stats{}.csv'.format(today))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'military_tagged.csv', 'consultants_tagged.csv']\n"
     ]
    }
   ],
   "source": [
    "# data_root = '/Users/connorchoi/Dropbox/global key advisors/Insider_Trading/Connor & Xueying/BioGroupStats/data_in/'\n",
    "data_root = '/Users/connorchoi/Dropbox/global key advisors/Insider_Trading/Insider_Trading_Connor/data_in'\n",
    "data_root_1 = '/Users/connorchoi/Dropbox/global key advisors/Insider_Trading/Insider_Trading_Connor/data_in/'\n",
    "    ##########################\n",
    "    # change file name to latest summary1's name\n",
    "    ##########################\n",
    "\n",
    "summary1 = read_raw_trans(data_root, 'summary1.txt', 'summary1 header.txt')\n",
    "summary1 = exclude_outliers(summary1, cols_to_trim=['return_12mo', 'net_return_1yr'])\n",
    "\n",
    "group_list = ['MBA','founder', 'academic', 'consultants', 'military', 'trader', 'all_groups']\n",
    "groups, found_files = get_insider_groups(group_list, data_root, 'TickerNameSECID.csv')\n",
    "\n",
    "\n",
    "bios = pd.read_table(os.path.join(data_root_1, 'all_bios_combined.csv'), sep=',', header=0, index_col=0)\n",
    "ticker = pd.read_table(os.path.join(data_root_1, 'TickerNameSECID.csv'), sep=',', header=0, index_col=0)\n",
    "bios = pd.merge(bios, ticker, how=\"inner\", on = \"Ticker\")\n",
    "\n",
    "bios['key'] = (bios['SEC_Company_ID'].apply(int).astype(str) + ',' + bios['ExecutiveSECID'].apply(int).astype(str))\n",
    "key_list = bios['key'].tolist()\n",
    "summary1['key'] = (summary1['SEC_Company_ID'].astype(str) + ',' + summary1['ExecutiveSECID'].astype(str))\n",
    "\n",
    "summary1 = summary1[summary1['key'].isin(key_list)]\n",
    "summary1.drop(['key'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "group_trans = []\n",
    "group_other_trans = []\n",
    "for df in groups:\n",
    "    df.dropna(inplace=True)\n",
    "    # financial sector included:\n",
    "    df_trans, df_other_trans = get_trans(df, summary1, financial=True)\n",
    "    group_trans.append(df_trans)\n",
    "    group_other_trans.append(df_other_trans)\n",
    "\n",
    "stats_titles = ['transaction count', 'mean', 'std', 'min.', '25pct', 'median',\n",
    "                '75pct', 'max.', 'beat count', 'beat/transaction', 'position']\n",
    "\n",
    "total_return_stats_df = stats_target_df(group_trans, group_other_trans,\n",
    "                                        found_files, 'return_12mo', stats_titles)\n",
    "total_return_stats_df.to_csv('data_out/Return12mo_stats{}.csv'.format(today))\n",
    "beating_stats_df = stats_target_df(group_trans, group_other_trans,\n",
    "                                   found_files, 'net_return_1yr', stats_titles)\n",
    "beating_stats_df.to_csv('data_out/Net_return_1yr_stats{}.csv'.format(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236832, 66)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_root = '/Users/connorchoi/Dropbox/global key advisors/Insider_Trading/Connor & Xueying/BioGroupStats/data_in/'\n",
    "data_root = '/Users/connorchoi/Dropbox/global key advisors/Insider_Trading/Insider_Trading_Connor/data_in'\n",
    "trans_df = pd.read_table(os.path.join(data_root, \"summary1.txt\"), sep=',', header=None)\n",
    "trans_df.shape\n",
    "# header = pd.read_table(os.path.join(root, file_head), sep=',', header=None)\n",
    "# trans_df.columns = list(header[0])\n",
    "# trans_df.dropna(inplace=True)\n",
    "# if 'Date' not in trans_df.columns:\n",
    "#     trans_df['Date'] = pd.to_datetime(\n",
    "#         (trans_df['Year'] * 10000 + trans_df['Month'] * 100 + trans_df['Day']).map(str))\n",
    "#     trans_df.drop(['Year', 'Month', 'Day', '16?'], axis=1, inplace=True)\n",
    "# if 'Position' not in trans_df.columns:\n",
    "#     trans_df = trans_df.rename(columns={'Position (Buy or Sell)': 'Position',\n",
    "#                                         'Options (Option related or not)': 'Options'})\n",
    "# if 'ExecutiveSECID' not in trans_df.columns:\n",
    "#     trans_df = trans_df.rename(columns={'SEC_Insider_ID': 'ExecutiveSECID'})\n",
    "\n",
    "# print(trans_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Ticker', 'Active', 'Comp_Name', 'Sector', 'Industry', 'Age',\n",
       "       'Position_held_since', 'ExecID', 'ReutersID', 'InsiderScore',\n",
       "       'ExecutiveSECID', 'InsiderHoldings', 'Description', 'Bio', 'Address',\n",
       "       'Phone', 'URL', 'Price_Current', 'MarketCap', 'dDate', 'Tag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grouped = pd.read_table(os.path.join(os.getcwd(), 'data_out/all_groups.csv'), sep=',', header=0, index_col=0)\n",
    "# grouped.head()\n",
    "\n",
    "data_root = '/Users/connorchoi/Dropbox/global key advisors/Insider_Trading/Insider_Trading_Connor/data_in/'\n",
    "bios = pd.read_table(os.path.join(data_root, 'all_bios_combined.csv'), sep=',', header=0, index_col=0)\n",
    "# bios = bios.rename(columns={'ExecutiveSECID': 'SEC_Company_ID'})\n",
    "# ticker = pd.read_table(os.path.join(data_root, 'TickerNameSECID.csv'), sep=',', header=0, index_col=0)\n",
    "# bios = pd.merge(bios, ticker, how=\"inner\", on = \"Ticker\")\n",
    "\n",
    "\n",
    "# bios.head()\n",
    "bios.columns\n",
    "\n",
    "# os.path.join(os.getcwd(), 'data_out/all_groups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186094, 66)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary1 = read_raw_trans(data_root, 'summary1.txt', 'summary1 header.txt')\n",
    "trans_df = summary1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_cut=1\n",
    "options=False\n",
    "market_cap_thre=0\n",
    "col_to_trim='return_12mo'\n",
    "thre_truncation=10\n",
    "iter_truncation=5\n",
    "thre_wins_upper=99\n",
    "thre_wins_lower=1\n",
    "\n",
    "if options is False:\n",
    "    trans_df = trans_df[(trans_df['price'] >= price_cut) & (trans_df['Options'] == 0)]\n",
    "else:\n",
    "    trans_df = trans_df[(trans_df['price'] >= price_cut)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = np.percentile(a=trans_df[col_to_trim], q=thre_wins_lower)\n",
    "upper_bound = np.percentile(a=trans_df[col_to_trim], q=thre_wins_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-78.6\n",
      "179.58800000000045\n"
     ]
    }
   ],
   "source": [
    "print(lower_bound)\n",
    "print(upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_df[col_to_trim + '_z'] = trans_df[col_to_trim].transform(lambda x: (x - x.mean()) / x.std())\n",
    "trans_df = trans_df[trans_df[col_to_trim + '_z'] < thre_truncation]\n",
    "iter_truncation = iter_truncation - 1\n",
    "\n",
    "trans_df.loc[trans_df[col_to_trim] >= upper_bound, col_to_trim] = upper_bound\n",
    "trans_df.loc[trans_df[col_to_trim] <= lower_bound, col_to_trim] = lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['academic.csv', '.DS_Store', 'net_return_1yr_stats_df20180319.csv', 'military.csv', 'all_groups.csv', 'Return12mo_stats2018-05-31.csv', 'consultants.csv', 'total_return_1yr_stats_df20180319.csv', 'founders2018-03-19.csv', 'Net_return_1yr_stats2018-05-31.csv', 'traders.csv']\n"
     ]
    }
   ],
   "source": [
    "root = data_root\n",
    "comp_secid = 'TickerNameSECID.csv'\n",
    "gp_list = group_list\n",
    "comp_secid_df = pd.read_csv(os.path.join(root, comp_secid), encoding='latin1')\n",
    "files = os.listdir(os.path.join(os.getcwd(), 'data_out'))\n",
    "print(files)\n",
    "gps = []\n",
    "found_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    if any(name in f for name in gp_list):\n",
    "        grouped_insider = pd.read_csv(os.path.join(os.getcwd(), 'data_out', f), index_col=0, encoding='latin1')\n",
    "        grouped_insider.dropna(inplace=True)\n",
    "        if 'SEC_Company_ID' not in grouped_insider.columns:\n",
    "            grouped_insider = grouped_insider.merge(comp_secid_df, on='Ticker', how='left')\n",
    "        gps.append(grouped_insider)\n",
    "        found_files.append(f.split('.')[0])\n",
    "if 'all_groups' not in found_files:\n",
    "    all_groups = pd.concat(gps)\n",
    "    all_groups = all_groups[['ExecutiveSECID', 'SEC_Company_ID']].drop_duplicates().dropna()\n",
    "    all_groups.to_csv(os.path.join(os.getcwd(), 'data_out/all_groups.csv'), encoding='utf-8')\n",
    "    gps.append(all_groups)\n",
    "    found_files.append('all_groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'academic'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'academic.csv'.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trans_df[[\"Aggregation_Count\",col_to_trim]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aggregation_Count</th>\n",
       "      <th>return_12mo</th>\n",
       "      <th>return_12mo_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.054588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.174184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>12</td>\n",
       "      <td>-5.3</td>\n",
       "      <td>-0.372712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.253117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>0.009993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Aggregation_Count  return_12mo  return_12mo_z\n",
       "221                  1          8.0      -0.054588\n",
       "238                  1          3.0      -0.174184\n",
       "243                 12         -5.3      -0.372712\n",
       "245                  1         -0.3      -0.253117\n",
       "256                  2         10.7       0.009993"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[col_to_trim + \"_z\"] = a[col_to_trim].transform(lambda x: (x - x.mean()) / x.std())\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aggregation_Count</th>\n",
       "      <th>return_12mo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>12</td>\n",
       "      <td>-5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Aggregation_Count  return_12mo\n",
       "221                  1          8.0\n",
       "238                  1          3.0\n",
       "243                 12         -5.3\n",
       "245                  1         -0.3\n",
       "256                  2         10.7"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
